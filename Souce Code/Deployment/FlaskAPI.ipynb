{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z25uUW8DgbDq",
        "outputId": "69c9800c-157f-498d-dbca-0d2b0d6ccff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --quiet install onnx onnxruntime onnxsim\n",
        "!pip install onnx-tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cNlk5pPhK3v",
        "outputId": "32466d7f-987e-4181-9833-008966d977a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onnx-tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.8/dist-packages (from onnx-tf) (1.13.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from onnx-tf) (6.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.20.2 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.10.2->onnx-tf) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.10.2->onnx-tf) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.10.2->onnx-tf) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->onnx-tf) (23.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->onnx-tf) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons, onnx-tf\n",
            "Successfully installed onnx-tf-1.10.0 tensorflow-addons-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask-restful"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5ByvXjChMJo",
        "outputId": "d5b346b9-36cb-42c6-a2eb-670fbd8232bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask-restful\n",
            "  Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from flask-restful) (1.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from flask-restful) (2022.7.1)\n",
            "Collecting aniso8601>=0.82\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.8/dist-packages (from flask-restful) (1.1.4)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-restful) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-restful) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-restful) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-restful) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-restful) (2.0.1)\n",
            "Installing collected packages: aniso8601, flask-restful\n",
            "Successfully installed aniso8601-9.0.1 flask-restful-0.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEQfR7JJhc-E",
        "outputId": "0c0584de-9e57-41b0-ec46-76894b6674b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-5.2.1.tar.gz (761 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m761.3/761.3 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.2.1-py3-none-any.whl size=19792 sha256=b069c6d0bb1a51e398f44ba94402ce82e66525ec6287694dd7ec20dc84692d06\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/f2/70/526da675d32f17577ec47ac4c663084efe39d47c826b6c3bb1\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-5.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir flask_app"
      ],
      "metadata": {
        "id": "Mgc1m3J-l_u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd flask_app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nMUxZ5-mCoi",
        "outputId": "7fa3ec8a-3c8e-4498-87fb-befa6497282b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flask_app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!touch app.py"
      ],
      "metadata": {
        "id": "HKw9wAgvmFT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy the code below into **app.py**"
      ],
      "metadata": {
        "id": "4Pea3i0_2I-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''from flask import Flask, request,jsonify\n",
        "from flask_restful import Api, Resource\n",
        "from pyngrok import ngrok\n",
        "import cv2\n",
        "import time\n",
        "import requests\n",
        "import random\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict,namedtuple\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.lib.type_check import imag\n",
        "import tensorflow as tf\n",
        "cuda = False\n",
        "plate_shape=(704,704)\n",
        "char_shape=(288,288)\n",
        "def letterbox(im, new_shape, color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
        "    # Resize and pad image while meeting stride-multiple constraints\n",
        "    shape = im.shape[:2]  # current shape [height, width]\n",
        "    if isinstance(new_shape, int):\n",
        "        new_shape = (new_shape, new_shape)\n",
        "\n",
        "    # Scale ratio (new / old)\n",
        "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
        "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
        "        r = min(r, 1.0)\n",
        "\n",
        "    # Compute padding\n",
        "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
        "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
        "\n",
        "    if auto:  # minimum rectangle\n",
        "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
        "\n",
        "    dw /= 2  # divide padding into 2 sides\n",
        "    dh /= 2\n",
        "\n",
        "    if shape[::-1] != new_unpad:  # resize\n",
        "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
        "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
        "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
        "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
        "    return im, r, (dw, dh)\n",
        "def init(img,classes,model,shape):\n",
        "  providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
        "  session = ort.InferenceSession(model, providers=providers)\n",
        "  im,r,(dw,dh)=letterbox(img,shape,auto=False)    # ex shape -> (704,704)\n",
        "  #Name of the classes according to class indices.\n",
        "  names = classes\n",
        "  #Creating random colors for bounding box visualization.\n",
        "  colors = {name:[int(random.randint(0, 255) * 0.2) for _ in range(3)] for i,name in enumerate(names)}\n",
        "  return providers,session,im,r,(dw,dh),names,colors\n",
        "def sortFn(li):\n",
        "  return li[0]\n",
        "def getCharacters(img):\n",
        "  classes=['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20',\n",
        "         '21','22','23','24','25','26']\n",
        "  model= \"/content/gdrive/MyDrive/bestLetters.onnx\"\n",
        "  #img = cv2.imread(image_path)\n",
        "  providers,session,im,r,(dw,dh),names,colors=init(img,classes,model,char_shape)\n",
        "  mg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  #Preprocessing the image for prediction.\n",
        "  image = img.copy()\n",
        "  image, ratio, dwdh = letterbox(image,char_shape, auto=False)\n",
        "  image = image.transpose((2, 0, 1))\n",
        "  image = np.expand_dims(image, 0)\n",
        "  image = np.ascontiguousarray(image)\n",
        "\n",
        "  im = image.astype(np.float32)\n",
        "  im /= 255\n",
        "  im.shape\n",
        "\n",
        "  #Getting onnx graph input and output names.\n",
        "  outname = [i.name for i in session.get_outputs()]\n",
        "  inname = [i.name for i in session.get_inputs()]\n",
        "  inp = {inname[0]:im}\n",
        "\n",
        "  # Running inference using session.\n",
        "  outputs = session.run(outname, inp)[0]\n",
        "\n",
        "  ori_images = [img.copy()]\n",
        "\n",
        "  labels=['أ','ب','ج','د','ر','س','ص','ط','ع','ف','ق','ل','م','ن','ھ','و','ى','٠','١','٢','٣','٤', '٥', '٦', '٧', '٨','٩']\n",
        "  dict_label={}\n",
        "  for char in labels:\n",
        "    dict_label[labels.index(char)]=char\n",
        "\n",
        "  number=[]\n",
        "  #Visualizing bounding box prediction.\n",
        "  for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
        "      image = ori_images[int(batch_id)]\n",
        "      box = np.array([x0,y0,x1,y1])\n",
        "      box -= np.array(dwdh*2)\n",
        "      box /= ratio\n",
        "      box = box.round().astype(np.int32).tolist()\n",
        "      box_coordinates=box.copy()\n",
        "      cls_id = int(cls_id)\n",
        "      score = round(float(score),3)\n",
        "      name = names[cls_id]\n",
        "      li=box.copy()\n",
        "      li.append(dict_label[int(name)])\n",
        "      number.append(li)\n",
        "      #color = colors[name]\n",
        "      #name += ' '+str(score)\n",
        "      #cv2.rectangle(image,box[:2],box[2:],color,2)\n",
        "      #cv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,color,thickness=2)\n",
        "\n",
        "  #plt.figure(dpi=150)\n",
        "  #plt.imshow(ori_images[0])\n",
        "  number.sort(key=sortFn)\n",
        "  return  number\n",
        "\n",
        "#Classification model\n",
        "def predict_vehicle_class(img):\n",
        "  model = tf.keras.models.load_model('/content/gdrive/MyDrive/car_classifier_VG16.h5')\n",
        "  class_name={0:'bus',1:'car', 2:'large_truck', 3:'microbus', 4:'mini_bus', 5:'semi_truck', 6:'truck'}\n",
        "  im=img.copy()\n",
        "  im= np.array(Image.fromarray(img).resize((224, 224)))\n",
        "  # expand the dimensions of the array to match the input shape of the model\n",
        "  img_array = np.expand_dims(im, axis=0)\n",
        "  # preprocess the image data to match the preprocessing used during training\n",
        "  img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
        "  # use the model to make a prediction on the image\n",
        "  prediction = model.predict(img_array)\n",
        "  return class_name[np.argmax(prediction)]\n",
        "\n",
        "def model(img):\n",
        "  classes=['License Plate']\n",
        "  model= \"/content/gdrive/MyDrive/bestPlate.onnx\"\n",
        "  #img = cv2.imread(image_path)\n",
        "  providers,session,im,r,(dw,dh),names,colors=init(img,classes,model,plate_shape)\n",
        "  for_croped = img.copy()\n",
        "  mg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  #Preprocessing the image for prediction.\n",
        "  image = img.copy()\n",
        "  image, ratio, dwdh = letterbox(image,plate_shape, auto=False)\n",
        "  image = image.transpose((2, 0, 1))\n",
        "  image = np.expand_dims(image, 0)\n",
        "  image = np.ascontiguousarray(image)\n",
        "\n",
        "  im = image.astype(np.float32)\n",
        "  im /= 255\n",
        "  im.shape\n",
        "\n",
        "  #Getting onnx graph input and output names.\n",
        "  outname = [i.name for i in session.get_outputs()]\n",
        "  inname = [i.name for i in session.get_inputs()]\n",
        "  inp = {inname[0]:im}\n",
        "\n",
        "  # Running inference using session.\n",
        "  outputs = session.run(outname, inp)[0]\n",
        "\n",
        "  ori_images = [img.copy()]\n",
        "  box_coordinates=[]\n",
        "  #Visualizing bounding box prediction.\n",
        "  for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
        "      image = ori_images[int(batch_id)]\n",
        "      box = np.array([x0,y0,x1,y1])\n",
        "      box -= np.array(dwdh*2)\n",
        "      box /= ratio\n",
        "      box = box.round().astype(np.int32).tolist()\n",
        "      box_coordinates=box.copy()\n",
        "      cls_id = int(cls_id)\n",
        "      score = round(float(score),3)\n",
        "      name = names[cls_id]\n",
        "      #color = colors[name]\n",
        "      name += ' '+str(score)\n",
        "      #cv2.rectangle(image,box[:2],box[2:],color,2)\n",
        "      x, y, w, h = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
        "      for_croped=for_croped[y:y+h, x:x+w]\n",
        "      #cv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,color,thickness=2)\n",
        "  plt.figure(dpi=150)\n",
        "  plt.imshow(ori_images[0])\n",
        "  number=getCharacters(for_croped)\n",
        "  _type=predict_vehicle_class(img)\n",
        "  return number,_type\n",
        "\n",
        "app = Flask(__name__)\n",
        "api = Api(app)\n",
        "class YOLOv7API(Resource):\n",
        "    def post(self):\n",
        "      # Get the image from the request\n",
        "      #image = request.files['image'].read()\n",
        "      #image = np.frombuffer(image, dtype='uint8')\n",
        "      img = Image.open(request.files['image'])\n",
        "      image= np.array(img)\n",
        "      boxes,_type = model(image)\n",
        "      results = []\n",
        "      for i in range(len(boxes)):\n",
        "        results.append({\n",
        "             'box': boxes[i][:4],\n",
        "             'class': boxes[i][4]\n",
        "           })\n",
        "      return dict({'License Number': results,'Vehicle Class':_type})\n",
        "api.add_resource(YOLOv7API, '/predict',methods=['GET', 'POST'])\n",
        "app.config['PROPAGATE_EXCEPTIONS'] = True\n",
        "if __name__ == '__main__':\n",
        "    #url = ngrok.connect(5000).public_url\n",
        "    url=ngrok.connect(5000, 'http', ngrok_address='http://56fc-34-86-75-112.ngrok.io')\n",
        "    print(' * Tunnel URL:', url)\n",
        "    # Start the Flask app and listen for requests\n",
        "    app.run(debug=False,host='0.0.0.0', port=5000)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "bvZNZM3ohFSa",
        "outputId": "e380b157-e3d6-4518-b2ad-28c6d23bb409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from flask import Flask, request,jsonify\\nfrom flask_restful import Api, Resource\\nfrom pyngrok import ngrok\\nimport cv2\\nimport time\\nimport requests\\nimport random\\nimport numpy as np\\nimport onnxruntime as ort\\nfrom PIL import Image\\nfrom pathlib import Path\\nfrom collections import OrderedDict,namedtuple\\nimport matplotlib.pyplot as plt\\nfrom numpy.lib.type_check import imag\\nimport tensorflow as tf\\ncuda = False\\nplate_shape=(704,704)\\nchar_shape=(288,288)\\ndef letterbox(im, new_shape, color=(114, 114, 114), auto=True, scaleup=True, stride=32):\\n    # Resize and pad image while meeting stride-multiple constraints\\n    shape = im.shape[:2]  # current shape [height, width]\\n    if isinstance(new_shape, int):\\n        new_shape = (new_shape, new_shape)\\n\\n    # Scale ratio (new / old)\\n    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\\n    if not scaleup:  # only scale down, do not scale up (for better val mAP)\\n        r = min(r, 1.0)\\n\\n    # Compute padding\\n    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\\n    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\\n\\n    if auto:  # minimum rectangle\\n        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\\n\\n    dw /= 2  # divide padding into 2 sides\\n    dh /= 2\\n\\n    if shape[::-1] != new_unpad:  # resize\\n        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\\n    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\\n    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\\n    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\\n    return im, r, (dw, dh)\\ndef init(img,classes,model,shape):\\n  providers = [\\'CUDAExecutionProvider\\', \\'CPUExecutionProvider\\'] if cuda else [\\'CPUExecutionProvider\\']\\n  session = ort.InferenceSession(model, providers=providers)\\n  im,r,(dw,dh)=letterbox(img,shape,auto=False)    # ex shape -> (704,704)\\n  #Name of the classes according to class indices.\\n  names = classes\\n  #Creating random colors for bounding box visualization.\\n  colors = {name:[int(random.randint(0, 255) * 0.2) for _ in range(3)] for i,name in enumerate(names)}\\n  return providers,session,im,r,(dw,dh),names,colors\\ndef sortFn(li):\\n  return li[0]\\ndef getCharacters(img):\\n  classes=[\\'0\\',\\'1\\',\\'2\\',\\'3\\',\\'4\\',\\'5\\',\\'6\\',\\'7\\',\\'8\\',\\'9\\',\\'10\\',\\'11\\',\\'12\\',\\'13\\',\\'14\\',\\'15\\',\\'16\\',\\'17\\',\\'18\\',\\'19\\',\\'20\\',\\n         \\'21\\',\\'22\\',\\'23\\',\\'24\\',\\'25\\',\\'26\\']\\n  model= \"/content/gdrive/MyDrive/bestLetters.onnx\"\\n  #img = cv2.imread(image_path)\\n  providers,session,im,r,(dw,dh),names,colors=init(img,classes,model,char_shape)\\n  mg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n\\n  #Preprocessing the image for prediction.\\n  image = img.copy()\\n  image, ratio, dwdh = letterbox(image,char_shape, auto=False)\\n  image = image.transpose((2, 0, 1))\\n  image = np.expand_dims(image, 0)\\n  image = np.ascontiguousarray(image)\\n\\n  im = image.astype(np.float32)\\n  im /= 255\\n  im.shape\\n\\n  #Getting onnx graph input and output names.\\n  outname = [i.name for i in session.get_outputs()]\\n  inname = [i.name for i in session.get_inputs()]\\n  inp = {inname[0]:im}\\n\\n  # Running inference using session.\\n  outputs = session.run(outname, inp)[0]\\n\\n  ori_images = [img.copy()]\\n\\n  labels=[\\'أ\\',\\'ب\\',\\'ج\\',\\'د\\',\\'ر\\',\\'س\\',\\'ص\\',\\'ط\\',\\'ع\\',\\'ف\\',\\'ق\\',\\'ل\\',\\'م\\',\\'ن\\',\\'ھ\\',\\'و\\',\\'ى\\',\\'٠\\',\\'١\\',\\'٢\\',\\'٣\\',\\'٤\\', \\'٥\\', \\'٦\\', \\'٧\\', \\'٨\\',\\'٩\\']\\n  dict_label={}\\n  for char in labels:\\n    dict_label[labels.index(char)]=char\\n\\n  number=[]\\n  #Visualizing bounding box prediction.\\n  for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\\n      image = ori_images[int(batch_id)]\\n      box = np.array([x0,y0,x1,y1])\\n      box -= np.array(dwdh*2)\\n      box /= ratio\\n      box = box.round().astype(np.int32).tolist()\\n      box_coordinates=box.copy()\\n      cls_id = int(cls_id)\\n      score = round(float(score),3)\\n      name = names[cls_id]\\n      li=box.copy()\\n      li.append(dict_label[int(name)])\\n      number.append(li)\\n      #color = colors[name]\\n      #name += \\' \\'+str(score)\\n      #cv2.rectangle(image,box[:2],box[2:],color,2)\\n      #cv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,color,thickness=2)  \\n       \\n  #plt.figure(dpi=150)\\n  #plt.imshow(ori_images[0])\\n  number.sort(key=sortFn)\\n  return  number\\n\\n#Classification model \\ndef predict_vehicle_class(img):\\n  model = tf.keras.models.load_model(\\'/content/gdrive/MyDrive/car_classifier_VG16.h5\\')\\n  class_name={0:\\'bus\\',1:\\'car\\', 2:\\'large_truck\\', 3:\\'microbus\\', 4:\\'mini_bus\\', 5:\\'semi_truck\\', 6:\\'truck\\'}\\n  im=img.copy()\\n  im= np.array(Image.fromarray(img).resize((224, 224)))\\n  # expand the dimensions of the array to match the input shape of the model\\n  img_array = np.expand_dims(im, axis=0)\\n  # preprocess the image data to match the preprocessing used during training\\n  img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\\n  # use the model to make a prediction on the image\\n  prediction = model.predict(img_array)\\n  return class_name[np.argmax(prediction)]\\n\\ndef model(img):\\n  classes=[\\'License Plate\\']\\n  model= \"/content/gdrive/MyDrive/bestPlate.onnx\"\\n  #img = cv2.imread(image_path)\\n  providers,session,im,r,(dw,dh),names,colors=init(img,classes,model,plate_shape)\\n  for_croped = img.copy()\\n  mg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n  #Preprocessing the image for prediction.\\n  image = img.copy()\\n  image, ratio, dwdh = letterbox(image,plate_shape, auto=False)\\n  image = image.transpose((2, 0, 1))\\n  image = np.expand_dims(image, 0)\\n  image = np.ascontiguousarray(image)\\n\\n  im = image.astype(np.float32)\\n  im /= 255\\n  im.shape\\n\\n  #Getting onnx graph input and output names.\\n  outname = [i.name for i in session.get_outputs()]\\n  inname = [i.name for i in session.get_inputs()]\\n  inp = {inname[0]:im}\\n\\n  # Running inference using session.\\n  outputs = session.run(outname, inp)[0]\\n\\n  ori_images = [img.copy()]\\n  box_coordinates=[]\\n  #Visualizing bounding box prediction.\\n  for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\\n      image = ori_images[int(batch_id)]\\n      box = np.array([x0,y0,x1,y1])\\n      box -= np.array(dwdh*2)\\n      box /= ratio\\n      box = box.round().astype(np.int32).tolist()\\n      box_coordinates=box.copy()\\n      cls_id = int(cls_id)\\n      score = round(float(score),3)\\n      name = names[cls_id]\\n      #color = colors[name]\\n      name += \\' \\'+str(score)\\n      #cv2.rectangle(image,box[:2],box[2:],color,2)\\n      x, y, w, h = box[0], box[1], box[2]-box[0], box[3]-box[1]\\n      for_croped=for_croped[y:y+h, x:x+w]\\n      #cv2.putText(image,name,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,color,thickness=2)  \\n  plt.figure(dpi=150)\\n  plt.imshow(ori_images[0])\\n  number=getCharacters(for_croped)\\n  _type=predict_vehicle_class(img)\\n  return number,_type\\n\\napp = Flask(__name__)\\napi = Api(app)\\nclass YOLOv7API(Resource):\\n    def post(self):\\n      # Get the image from the request\\n      #image = request.files[\\'image\\'].read()\\n      #image = np.frombuffer(image, dtype=\\'uint8\\')\\n      img = Image.open(request.files[\\'image\\'])\\n      image= np.array(img)\\n      boxes,_type = model(image)\\n      results = []\\n      for i in range(len(boxes)):\\n        results.append({\\n             \\'box\\': boxes[i][:4],\\n             \\'class\\': boxes[i][4] \\n           })\\n      return dict({\\'License Number\\': results,\\'Vehicle Class\\':_type})\\napi.add_resource(YOLOv7API, \\'/predict\\',methods=[\\'GET\\', \\'POST\\'])\\napp.config[\\'PROPAGATE_EXCEPTIONS\\'] = True\\nif __name__ == \\'__main__\\':\\n    #url = ngrok.connect(5000).public_url\\n    url=ngrok.connect(5000, \\'http\\', ngrok_address=\\'http://56fc-34-86-75-112.ngrok.io\\')\\n    print(\\' * Tunnel URL:\\', url)\\n    # Start the Flask app and listen for requests\\n    app.run(debug=False,host=\\'0.0.0.0\\', port=5000)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEwHbEfamMFJ",
        "outputId": "b9e59b36-4d81-4984-a0c9-259f9024ce25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-20 20:18:15.673700: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-20 20:18:16.960047: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-20 20:18:16.960185: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-02-20 20:18:16.960209: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            " * Tunnel URL: NgrokTunnel: \"http://c7f9-34-125-247-117.ngrok.io\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app \"app\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            "INFO:werkzeug: * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
            "2023-02-20 20:18:40.490484: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Feb/2023 20:18:43] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "1/1 [==============================] - 1s 639ms/step\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Feb/2023 20:18:49] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Feb/2023 20:18:56] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "1/1 [==============================] - 1s 625ms/step\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Feb/2023 20:19:03] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XB7MjRQM2ohD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}